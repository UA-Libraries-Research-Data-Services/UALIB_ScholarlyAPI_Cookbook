{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# College Scorecard API in C\n",
    "\n",
    "by Cyrus Gomes and Avery Fernandez\n",
    "\n",
    "**College Scorecard API documentation:** https://collegescorecard.ed.gov/data/data-documentation/\n",
    "\n",
    "**College Scorecard Copyright Status:** https://www2.ed.gov/notices/copyright/index.html\n",
    "\n",
    "<br>\n",
    "\n",
    "The College Scorecard API is an online tool hosted by the U.S. Department of Education that contains data concerning higher education institutions.\n",
    "\n",
    "These recipe examples were tested on August 23, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, install the CURL and jq packages by typing the following command in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install curl jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir College_Scorecard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change to the newly created directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd College_Scorecard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a variable for API Key\n",
    "\n",
    "An API key is required to access the College Scorecard API. This API key can be obtained [here](https://collegescorecard.ed.gov/data/api-documentation#api-access-and-authentication).\n",
    "\n",
    "Save your API key to a separate text file, then create a variable for your key. Avoid displaying your API key in your terminal (to prevent accidental sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the key file\n",
    "!touch \"apiKey.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following command to access the key as Jupyter does not allow variable sharing for bash scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the key into the file by copy/paste or keying in manually\n",
    "# Read the key from the file\n",
    "!apiKey=$(cat \"apiKey.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `%%file` command to create the following makefile which will compile our program and create an executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing makefile\n"
     ]
    }
   ],
   "source": [
    "%%file makefile\n",
    "\n",
    "# Set the variable CC to gcc, which is used to build the program\n",
    "CC=gcc\n",
    "\n",
    "# Enable debugging information and enable all compiler warnings\n",
    "CFLAGS=-g -Wall\n",
    "\n",
    "# Set the bin variable as the name of the binary file we are creating\n",
    "BIN=college_score\n",
    "\n",
    "# Create the binary file with the name we put\n",
    "all: $(BIN)\n",
    "\n",
    "# Map any file ending in .c to a binary executable. \n",
    "# \"$<\" represents the .c file and \"$@\" represents the target binary executable\n",
    "%: %.c\n",
    "\n",
    "\t# Compile the .c file using the gcc compiler with the CFLAGS and links \n",
    "\t# resulting binary with the CURL library\n",
    "\t$(CC) $(CFLAGS) $< -o $@ -lcurl\n",
    "\n",
    "# Clean target which removes specific files\n",
    "clean:\n",
    "\n",
    "\t# Remove the binary file and an \".dSYM\" (debug symbols for debugging) directories\n",
    "\t# the RM command used -r to remove directories and -f to force delete\n",
    "\t$(RM) -rf $(BIN) *.dSYM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command is used again to create our .c file which contains the code for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./college_score.c\n"
     ]
    }
   ],
   "source": [
    "%%file ./college_score.c\n",
    "\n",
    "#include <curl/curl.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "\n",
    "/*CURL program that retrieves College Scorecard data from\n",
    "  http://api.data.gov/ed/collegescorecard/v1/ */\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "\n",
    "    // Return if arguments are invalid\n",
    "    if (argc < 2 || argc > 3) {                                                                                      \n",
    "    printf(\"Error. Please try again correctly. (./college_score -url [url])\\n\");\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    // Initialize CURL HTTP connection\n",
    "    CURL *curl = curl_easy_init();\n",
    "    if (!curl) {\n",
    "        fprintf(stderr, \"CURL initialization failed\\n\");\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    char link[] = \"http://api.data.gov/ed/collegescorecard/v1/schools?fields=\";\n",
    "    char url[1000];\n",
    "    \n",
    "    if ((argc==2) && (strcmp(argv[1], \"-url\")==0)) {\n",
    "        sprintf(url, \"%s\", link);\n",
    "    }\n",
    "\n",
    "    else if ((argc==3) && (strcmp(argv[1], \"-url\")==0)) {\n",
    "        sprintf(url, \"%s\", argv[2]);\n",
    "    }\n",
    "\n",
    "    // Set the URL to which the HTTP request will be sent\n",
    "    curl_easy_setopt(curl, CURLOPT_URL, url);\n",
    "\n",
    "    // Set option to follow redirections\n",
    "    curl_easy_setopt(curl, CURLOPT_FOLLOWLOCATION, 1L);\n",
    "\n",
    "    // Perform the HTTP request\n",
    "    CURLcode result = curl_easy_perform(curl);\n",
    "\n",
    "    // Check if the request was successful\n",
    "    if (result != CURLE_OK) {\n",
    "        fprintf(stderr, \"Download problem: %s\\n\", curl_easy_strerror(result));\n",
    "    }\n",
    "\n",
    "    // Cleanup and resource deallocation\n",
    "    curl_easy_cleanup(curl);\n",
    "    return EXIT_SUCCESS;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Compile the .c file using the gcc compiler with the CFLAGS and links \n",
      "# resulting binary with the CURL library\n",
      "gcc -g -Wall college_score.c -o college_score -lcurl\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get names of all institutions\n",
    "\n",
    "To start, we'll use a basic query to find the names of all educational institutions recognized by the College Scorecard API.\n",
    "\n",
    "All of the data for the API can be found using the `v1/schools` endpoint.\n",
    "\n",
    "Fields in the College Scorecard API are accessed with a `<time>.<category>.<name>` sequence:\n",
    "- `<time>` indicates the year of the data to be accessed. To access the most recent data, use `latest`.\n",
    "- `<category>` and `<name>` can be found in the Data Dictionary file that can be downloaded from the API's documentation. The `<category>` of a field is given by the `dev-category` column in the `Institution_Data_Dictionary` section, and the `<name>` is given by the `developer-friendly name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"page\": 0,\n",
      "  \"total\": 6484,\n",
      "  \"per_page\": 20\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Store the key\n",
    "key=$(cat apiKey.txt)\n",
    "\n",
    "# Store the field name\n",
    "field='school.name'\n",
    "\n",
    "# Store the url\n",
    "url=\"http://api.data.gov/ed/collegescorecard/v1/schools?fields=${field}&api_key=${key}\"\n",
    "\n",
    "# Call the API to retrieve the metadata\n",
    "names=$(./college_score -url \"$url\" | jq '.[\"metadata\"]')\n",
    "\n",
    "echo \"$names\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `total` value indicates the total number results returned in this query. These results are paginated, so each query will return only the number indicated by `page_size`, which has a default value of 20 and a maximum value of 100. The page number is indicated by `page`, which by default is set to 0.\n",
    "\n",
    "We can use a loop to create an API request for each page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6484\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Declare url parameters\n",
    "field='school.name'\n",
    "sort_key='school.name'\n",
    "page_size='100'\n",
    "\n",
    "# Store the key in the key variable\n",
    "key=$(cat apiKey.txt)\n",
    "\n",
    "# Attach the key to the url\n",
    "url=\"http://api.data.gov/ed/collegescorecard/v1/schools?api_key=${key}\"\n",
    "\n",
    "# Call the API and retrieve the metadata\n",
    "metadata_tot=$(./college_score -url \"$url\" | jq '.[\"metadata\"][\"total\"]')\n",
    "\n",
    "# Calculate the total number of pages\n",
    "total_pages=$(((metadata_tot + 1) / page_size + 1 ))\n",
    "\n",
    "# Loop through each page of the dataset, sending a request for each page\n",
    "for ((page_number = 0; page_number < total_pages; page_number++)); do\n",
    "    # Combine the parameters to create a working url\n",
    "    url2=\"http://api.data.gov/ed/collegescorecard/v1/schools?fields=${field}&page=${page_number}&per_page=${page_size}&sort=${sort_key}&api_key=${key}\"\n",
    "\n",
    "    # Retrieve the school names\n",
    "    name_data=$(./college_score -url \"$url2\" | jq '.results[] | .\"school.name\"')\n",
    "\n",
    "    # Output the school names to a .txt file\n",
    "    echo \"$name_data\" >> institution_names.txt\n",
    "\n",
    "    # Wait 1 second between API calls to be nicer on the host servers\n",
    "    sleep 1\n",
    "\n",
    "done\n",
    "\n",
    "# Print number of institution names found\n",
    "cat institution_names.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A Better U Beauty Barber Academy\"\n",
      "\"A T Still University of Health Sciences\"\n",
      "\"Aaniiih Nakoda College\"\n",
      "\"ABC Adult School\"\n",
      "\"ABC Adult School - Cabrillo Lane\"\n",
      "\"ABC Beauty Academy\"\n",
      "\"ABCO Technology\"\n",
      "\"Abcott Institute\"\n",
      "\"Abilene Christian University\"\n",
      "\"Abilene Christian University-Undergraduate Online\"\n"
     ]
    }
   ],
   "source": [
    "# Print first 10 results\n",
    "!head -n 10 institution_names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get names of all universities\n",
    "\n",
    "College Scorecard API requests can also take conditions to only select certain institutions.\n",
    "\n",
    "In this example, we limit the results to only include institutions that award graduate degrees. In order to do this, we set the `degrees_awarded.highest` parameter to `4` to indicate that the highest degree awarded by an instition is a graduate degree. This information is within the `Institution_Data_Dictionary` section of the College Scorecard data disctionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1986\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Declare url parameters\n",
    "condition='latest.school.degrees_awarded.highest=4'\n",
    "field='school.name'\n",
    "sort_key='school.name'\n",
    "page_size='100'\n",
    "\n",
    "# Store the key\n",
    "key=$(cat apiKey.txt)\n",
    "\n",
    "# Attach the key to the url\n",
    "url=\"http://api.data.gov/ed/collegescorecard/v1/schools?${condition}&fields=${field}&api_key=${key}\"\n",
    "\n",
    "# Call the API and retrieve the metadata\n",
    "metadata_tot=$(./college_score -url \"$url\" | jq '.[\"metadata\"][\"total\"]')\n",
    "\n",
    "# Calculate total number of pages\n",
    "total_pages=$(((metadata_tot + 1) / page_size + 1 ))\n",
    "\n",
    "# Loop through each page of the dataset, sending a request for each page\n",
    "for ((page_number = 0; page_number <= total_pages; page_number++)); do\n",
    "    # Combine the parameters to create a working url\n",
    "    url2=\"http://api.data.gov/ed/collegescorecard/v1/schools?${condition}&fields=${field}&page=${page_number}&per_page=${page_size}&sort=${sort_key}&api_key=${key}\"\n",
    "\n",
    "    # Retrieve the school names\n",
    "    name_data=$(./college_score -url \"$url2\" | jq '.results[] | .\"school.name\"')\n",
    "\n",
    "    # Output the school names to a .txt file\n",
    "    echo \"$name_data\" >> university_names.txt\n",
    "\n",
    "    # Wait 1 second between API calls to be nicer on the host servers\n",
    "    sleep 1\n",
    "\n",
    "done\n",
    "\n",
    "# Print number of university names found\n",
    "cat university_names.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A T Still University of Health Sciences\"\n",
      "\"Abilene Christian University\"\n",
      "\"Abraham Lincoln University\"\n",
      "\"Academy for Five Element Acupuncture\"\n",
      "\"Academy for Jewish Religion\"\n",
      "\"Academy for Jewish Religion-California\"\n",
      "\"Academy of Art University\"\n",
      "\"Academy of Chinese Culture and Health Sciences\"\n",
      "\"Academy of Vocal Arts\"\n",
      "\"Acupuncture and Integrative Medicine College-Berkeley\"\n"
     ]
    }
   ],
   "source": [
    "# Print first 10 results\n",
    "!head -n 10 university_names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find number of universities by state\n",
    "\n",
    "The `school.state_fips` data element contains a number that corresponds to each state. This mapping is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "states='{\n",
    "\"1\": \"Alabama\",\n",
    "\"2\": \"Alaska\",\n",
    "\"4\": \"Arizona\",\n",
    "\"5\": \"Arkansas\",\n",
    "\"6\": \"California\",\n",
    "\"8\": \"Colorado\",\n",
    "\"9\": \"Connecticut\",\n",
    "\"10\": \"Delaware\",\n",
    "\"11\": \"District of Columbia\",\n",
    "\"12\": \"Florida\",\n",
    "\"13\": \"Georgia\",\n",
    "\"15\": \"Hawaii\",\n",
    "\"16\": \"Idaho\",\n",
    "\"17\": \"Illinois\",\n",
    "\"18\": \"Indiana\",\n",
    "\"19\": \"Iowa\",\n",
    "\"20\": \"Kansas\",\n",
    "\"21\": \"Kentucky\",\n",
    "\"22\": \"Louisiana\",\n",
    "\"23\": \"Maine\",\n",
    "\"24\": \"Maryland\",\n",
    "\"25\": \"Massachusetts\",\n",
    "\"26\": \"Michigan\",\n",
    "\"27\": \"Minnesota\",\n",
    "\"28\": \"Mississippi\",\n",
    "\"29\": \"Missouri\",\n",
    "\"30\": \"Montana\",\n",
    "\"31\": \"Nebraska\",\n",
    "\"32\": \"Nevada\",\n",
    "\"33\": \"New Hampshire\",\n",
    "\"34\": \"New Jersey\",\n",
    "\"35\": \"New Mexico\",\n",
    "\"36\": \"New York\",\n",
    "\"37\": \"North Carolina\",\n",
    "\"38\": \"North Dakota\",\n",
    "\"39\": \"Ohio\",\n",
    "\"40\": \"Oklahoma\",\n",
    "\"41\": \"Oregon\",\n",
    "\"42\": \"Pennsylvania\",\n",
    "\"44\": \"Rhode Island\",\n",
    "\"45\": \"South Carolina\",\n",
    "\"46\": \"South Dakota\",\n",
    "\"47\": \"Tennessee\",\n",
    "\"48\": \"Texas\",\n",
    "\"49\": \"Utah\",\n",
    "\"50\": \"Vermont\",\n",
    "\"51\": \"Virginia\",\n",
    "\"53\": \"Washington\",\n",
    "\"54\": \"West Virginia\",\n",
    "\"55\": \"Wisconsin\",\n",
    "\"56\": \"Wyoming\",\n",
    "\"60\": \"American Samoa\",\n",
    "\"64\": \"Federated States of Micronesia\",\n",
    "\"66\": \"Guam\",\n",
    "\"69\": \"Northern Mariana Islands\",\n",
    "\"70\": \"Palau\",\n",
    "\"72\": \"Puerto Rico\",\n",
    "\"78\": \"Virgin Islands\"\n",
    "}'\n",
    "\n",
    "echo \"$states\" > states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this mapping, we can find the number of universities in each state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Alabama\" 30\n",
      "\"Alaska\" 4\n",
      "\"Arizona\" 22\n",
      "\"Arkansas\" 20\n",
      "\"California\" 208\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Declare an associative array\n",
    "declare -A state_frequency\n",
    "\n",
    "# Declare the parameters for the url\n",
    "condition='latest.school.degrees_awarded.highest=4'\n",
    "field='latest.school.state_fips'\n",
    "page_size='100'\n",
    "\n",
    "# Store the key\n",
    "key=$(cat apiKey.txt)\n",
    "\n",
    "# Attach the key to the url\n",
    "url=\"http://api.data.gov/ed/collegescorecard/v1/schools?${condition}&fields=${field}&api_key=${key}\"\n",
    "\n",
    "# Call the API and retrieve the metadata\n",
    "metadata_tot=$(./college_score -url \"$url\" | jq '.[\"metadata\"][\"total\"]')\n",
    "\n",
    "# Calculate total number of pages\n",
    "total_pages=$(((metadata_tot + 1) / page_size + 1 ))\n",
    "\n",
    "# Loop through each page of the dataset, sending a request for each page\n",
    "for ((page_number = 0; page_number < total_pages; page_number++)); do\n",
    "    # Combine the parameters to create a working url\n",
    "    url2=\"http://api.data.gov/ed/collegescorecard/v1/schools?${condition}&fields=${field}&page=${page_number}&per_page=${page_size}&api_key=${key}\"\n",
    "\n",
    "    # Retrieve the school names\n",
    "    state_data=$(./college_score -url \"$url2\" | jq '.results[] | .\"latest.school.state_fips\"')\n",
    "\n",
    "    # Output the frequency to a text file\n",
    "    echo \"$state_data\" >> frequencies.txt\n",
    "\n",
    "    # Clear the state_data variable\n",
    "    unset state_data\n",
    "\n",
    "    # Wait 1 second between API calls to be nicer on the host servers\n",
    "    sleep 1\n",
    "\n",
    "done\n",
    "\n",
    "# Replace the numbers in frequencies.txt with States in the file \n",
    "while IFS= read -r line; do\n",
    "    # Append each line to the result variable\n",
    "    result=$(cat states | jq '.[\"'\"$line\"'\"]')\n",
    "    echo \"$result\" >> state_freq.txt\n",
    "done < \"frequencies.txt\"\n",
    "\n",
    "# Create a table with state and frequencies for that specific state, whilst sorting the states\n",
    "sort state_freq.txt | uniq -c | awk '{print $2, $1}' > final_output.txt\n",
    "\n",
    "# Print the top 5 results alphabetically\n",
    "cat final_output.txt | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can sort and display the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"California\" 208\n",
      "\"New 155\n",
      "\"Pennsylvania\" 109\n",
      "\"Texas\" 105\n",
      "\"Illinois\" 81\n",
      "\"Florida\" 75\n",
      "\"Massachusetts\" 73\n",
      "\"Ohio\" 65\n",
      "\"Missouri\" 56\n",
      "\"North 55\n",
      "\"Virginia\" 52\n",
      "\"Georgia\" 50\n",
      "\"Indiana\" 49\n",
      "\"Puerto 48\n",
      "\"Tennessee\" 47\n",
      "\"Michigan\" 45\n",
      "\"Wisconsin\" 40\n",
      "\"Minnesota\" 38\n",
      "\"New 38\n",
      "\"South 33\n",
      "\"Alabama\" 30\n",
      "\"Kentucky\" 30\n",
      "\"Colorado\" 29\n",
      "\"Maryland\" 29\n",
      "\"Oregon\" 28\n",
      "\"Washington\" 28\n",
      "\"Iowa\" 27\n",
      "\"Louisiana\" 27\n",
      "\"Connecticut\" 26\n",
      "\"Kansas\" 25\n",
      "\"Oklahoma\" 25\n",
      "\"Arizona\" 22\n",
      "\"Arkansas\" 20\n",
      "\"Nebraska\" 20\n",
      "\"West 18\n",
      "\"District 16\n",
      "\"Maine\" 16\n",
      "\"Mississippi\" 15\n",
      "\"South 15\n",
      "\"Vermont\" 14\n",
      "\"New 13\n",
      "\"New 13\n",
      "\"Utah\" 13\n",
      "\"Rhode 12\n",
      "\"North 11\n",
      "\"Idaho\" 8\n",
      "\"Nevada\" 8\n",
      "\"Montana\" 7\n",
      "\"Hawaii\" 6\n",
      "\"Delaware\" 5\n",
      "\"Alaska\" 4\n",
      "\"Guam\" 1\n",
      "\"Virgin 1\n",
      "\"Wyoming\" 1\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the state and frequencies from highest to lowest\n",
    "!sort -k2,2rn final_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Retrieving multiple data points in a single query\n",
    "\n",
    "The following example uses multiple conditions and multiple fields. The conditions in the query are separated by `&` while the fields are separated by `,`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\tAdmission Rate\tSize\tTuition Out of State\tTuition In State\tMedian Household Income\tEndowment\n",
      "Alabama A & M University\t0.684\t5196\t18634\t10024\t49720\tnull\n",
      "University of Alabama at Birmingham\t0.8668\t12776\t21216\t8832\t55735\t711616804\n",
      "University of Alabama in Huntsville\t0.781\t6985\t24770\t11878\t58688\t100321016\n",
      "Alabama State University\t0.966\t3296\t19396\t11068\t46065\t130589167\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Declare an array\n",
    "conditions=(\n",
    "    'latest.school.degrees_awarded.highest=4'\n",
    "    'latest.student.size__range=1000..'\n",
    ")\n",
    "\n",
    "# Set the IFS to '&' (the separator)\n",
    "IFS='&'\n",
    "\n",
    "# Join the array elements using the separator\n",
    "conditions_string=\"${conditions[*]}\"\n",
    "\n",
    "# Reset the IFS to its default value\n",
    "unset IFS\n",
    "\n",
    "fields=(\n",
    "    'school.name'\n",
    "    'latest.admissions.admission_rate.overall'\n",
    "    'latest.student.size'\n",
    "    'latest.cost.tuition.out_of_state'\n",
    "    'latest.cost.tuition.in_state'\n",
    "    'latest.student.demographics.median_hh_income'\n",
    "    'latest.school.endowment.begin'\n",
    ")\n",
    "\n",
    "# Set the IFS to ',' (the separator)\n",
    "IFS=','\n",
    "\n",
    "# Join the array elements using the separator\n",
    "fields_string=\"${fields[*]}\"\n",
    "\n",
    "# Reset the IFS to its default value\n",
    "unset IFS\n",
    "\n",
    "# Declare parameters\n",
    "key=$(cat apiKey.txt)\n",
    "page_size='100'\n",
    "sort_key='school.name'\n",
    "\n",
    "# Attach the key to the url\n",
    "url=\"http://api.data.gov/ed/collegescorecard/v1/schools?${condition}&fields=${field}&api_key=${key}\"\n",
    "\n",
    "# Call the API and retrieve the metadata\n",
    "metadata_tot=$(./college_score -url \"$url\" | jq '.[\"metadata\"][\"total\"]')\n",
    "\n",
    "# Calculate total number of pages\n",
    "total_pages=$(((metadata_tot + 1) / page_size + 1 ))\n",
    "\n",
    "# Create the headers for the table and put it in data.tsv\n",
    "echo -e \"Name\\tAdmission Rate\\tSize\\tTuition Out of State\\tTuition In State\\tMedian Household Income\\tEndowment\" >> data.tsv\n",
    "\n",
    "# Loop through each page of the dataset, sending a request for each page\n",
    "for ((page_number = 0; page_number < total_pages; page_number++)); do\n",
    "    # Combine the parameters to create a working url\n",
    "    url2=\"http://api.data.gov/ed/collegescorecard/v1/schools?${conditions_string}&fields=${fields_string}&page=${page_number}&per_page=${page_size}&api_key=${key}\"\n",
    "\n",
    "    # Retrieve the school names\n",
    "    university_data=$(./college_score -url \"$url2\" | jq '.results[]')\n",
    "\n",
    "    # Unset JSON array\n",
    "    unset json_array\n",
    "\n",
    "    # Split the JSON data into separate JSON objects\n",
    "    IFS=$'\\n' read -r -d '' -a json_objects <<< \"$(echo \"$university_data\" | jq -c '.')\"\n",
    "\n",
    "    # Store the JSON objects in an array\n",
    "    for obj in \"${json_objects[@]}\"; do\n",
    "        json_array+=(\"$obj\")\n",
    "    done\n",
    "\n",
    "    # Print the array elements\n",
    "    for ((i = 0; i < ${#json_array[@]}; i++)); do\n",
    "        tsv_data=$(echo \"${json_array[i]}\" | jq -r '[ .[\"school.name\"], (.[\"latest.admissions.admission_rate.overall\"] | tostring), (.[\"latest.student.size\"] | tostring), (.[\"latest.cost.tuition.out_of_state\"] | tostring), (.[\"latest.cost.tuition.in_state\"] | tostring), (.[\"latest.student.demographics.median_hh_income\"] | tostring), (.[\"latest.school.endowment.begin\"] | tostring) ] | join(\"\\t\")')\n",
    "        echo \"$tsv_data\" >> data.tsv\n",
    "    done\n",
    "\n",
    "    # Wait 1 second between API calls to be nicer on the host servers\n",
    "    sleep 1\n",
    "\n",
    "done\n",
    "\n",
    "# Print first 5 results of the TSV\n",
    "cat data.tsv | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query the resulting TSV file to find the data for specific universities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama State University\t0.966\t3296\t19396\t11068\t46065\t130589167\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Row to be retrieved\n",
    "row=$(cat data.tsv | grep \"Alabama State University\")\n",
    "\n",
    "# Print the retrieved row\n",
    "echo \"$row\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query the dataframe to find the data for universities that satisfy certain conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown University\t0.0506\t7222\t65146\t65146\t79027\t6520175000\n",
      "Columbia University in the City of New York\t0.0395\t8902\t66139\t66139\t76971\t14349970000\n",
      "Cornell University\t0.0747\t15676\t63200\t63200\t80346\t9485887743\n",
      "Dartmouth College\t0.0638\t4412\t62658\t62658\t79834\t8484189450\n",
      "Duke University\t0.0635\t6570\t62688\t62688\t78468\t12692472000\n",
      "Harvard University\t0.0324\t7973\t57261\t57261\t76879\t53165753000\n",
      "Johns Hopkins University\t0.0725\t5643\t60480\t60480\t81539\t9315279000\n",
      "Massachusetts Institute of Technology\t0.0396\t4638\t57986\t57986\t77426\t27394039000\n",
      "Northeastern University\t0.068\t16172\t60192\t60192\t80190\t1365215950\n",
      "Northwestern University\t0.0721\t8837\t63468\t63468\t81811\t11361182000\n",
      "Princeton University\t0.057\t5527\t57410\t57410\t81428\t37026442000\n",
      "Rice University\t0.0868\t4480\t54960\t54960\t77707\t8080292000\n",
      "Stanford University\t0.0368\t7761\t58416\t58416\t80275\t37788187000\n",
      "Tufts University\t0.0969\t6747\t65222\t65222\t82793\t2646506000\n",
      "University of California-Los Angeles\t0.0857\t32423\t43473\t13401\t72896\t3161977000\n",
      "University of Chicago\t0.0543\t7511\t64260\t64260\t74573\t9594956009\n",
      "University of Pennsylvania\t0.065\t10572\t63452\t63452\t78252\t20523546000\n",
      "Vanderbilt University\t0.0667\t7144\t60348\t60348\t76279\t10928512332\n",
      "Williams College\t0.085\t2138\t61770\t61770\t77966\t3911574095\n",
      "Yale University\t0.0457\t6639\t62250\t62250\t75345\t42282852000\n"
     ]
    }
   ],
   "source": [
    "# $1 - Name\n",
    "# $2 - Admission Rate\n",
    "# $3 - Size\n",
    "# $4 - Enrollment\n",
    "# $5 - Tuition Out of State\n",
    "# $6 - Tuition In State\n",
    "# $7 - Median Household Income Endowment\n",
    "\n",
    "# Use awk to filter rows to only include universities with an admission rate under 10%\n",
    "!awk -F'\\t' '$2 < 0.1' data.tsv | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columbia University in the City of New York\t0.0395\t8902\t66139\t66139\t76971\t14349970000\n",
      "Duke University\t0.0635\t6570\t62688\t62688\t78468\t12692472000\n",
      "Emory University\t0.1135\t7017\t57948\t57948\t80509\t12218692520\n",
      "Harvard University\t0.0324\t7973\t57261\t57261\t76879\t53165753000\n",
      "Massachusetts Institute of Technology\t0.0396\t4638\t57986\t57986\t77426\t27394039000\n",
      "Northwestern University\t0.0721\t8837\t63468\t63468\t81811\t11361182000\n",
      "Princeton University\t0.057\t5527\t57410\t57410\t81428\t37026442000\n",
      "Stanford University\t0.0368\t7761\t58416\t58416\t80275\t37788187000\n",
      "Texas A & M University-College Station\t0.6265\t56792\t40139\t13239\t67194\t16895619110\n",
      "University of Michigan-Ann Arbor\t0.1769\t32448\t55334\t16736\t77145\t16795776000\n",
      "University of Notre Dame\t0.1291\t8917\t60301\t60301\t76710\t18385354000\n",
      "University of Pennsylvania\t0.065\t10572\t63452\t63452\t78252\t20523546000\n",
      "University of Virginia-Main Campus\t0.1866\t17103\t55914\t20342\t79524\t10366577975\n",
      "Vanderbilt University\t0.0667\t7144\t60348\t60348\t76279\t10928512332\n",
      "Washington University in St Louis\t0.1176\t7801\t60590\t60590\t79298\t13668081000\n",
      "Yale University\t0.0457\t6639\t62250\t62250\t75345\t42282852000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Specify the endowment in scientific notation\n",
    "Endowment='1.0e+10'  \n",
    "\n",
    "# Convert scientific notation to integer\n",
    "Endowment_int=$(printf \"%.0f\" \"$Endowment\")\n",
    "\n",
    "# Use awk to compare the endowment value in data.tsv with the integer value\n",
    "awk -v endowment=\"$Endowment_int\" -F'\\t' 'NR > 1 && $7 > endowment && $7 != \"null\"' data.tsv | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieving all data for an institution\n",
    "\n",
    "The College Scorecard API can also be used to retrieve all of the data for a particular institution. The example below finds all data for The University of Alabama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metadata\": {\n",
      "    \"page\": 0,\n",
      "    \"total\": 1,\n",
      "    \"per_page\": 20\n",
      "  },\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"latest\": {\n",
      "        \"school\": {\n",
      "          \"zip\": \"35487-0100\",\n",
      "          \"city\": \"Tuscaloosa\",\n",
      "          \"name\": \"The University of Alabama\",\n",
      "          \"alias\": null,\n",
      "          \"state\": \"AL\",\n",
      "          \"locale\": 13,\n",
      "          \"address\": \"739 University Blvd\",\n",
      "          \"dolflag\": 1,\n",
      "          \"branches\": 1,\n",
      "          \"men_only\": 0,\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Store the key\n",
    "key=$(cat apiKey.txt)\n",
    "\n",
    "# Set the condition and url encode it\n",
    "condition='school.name=The%20University%20of%20Alabama'\n",
    "\n",
    "# Store the url\n",
    "url=\"http://api.data.gov/ed/collegescorecard/v1/schools?${condition}&api_key=${key}\"\n",
    "\n",
    "# Call the API and retrieve the metadata\n",
    "api_data=$(./college_score -url \"$url\" | jq '.')\n",
    "\n",
    "# Print first 20 lines of the result\n",
    "echo \"$api_data\" | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll look at the breakdown of size of each program at the University of Alabama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"business_marketing\": 0.2868,\n",
      "  \"engineering\": 0.1235,\n",
      "  \"health\": 0.1008,\n",
      "  \"communication\": 0.0944,\n",
      "  \"family_consumer_science\": 0.0798,\n",
      "  \"social_science\": 0.0786,\n",
      "  \"psychology\": 0.0403,\n",
      "  \"biological\": 0.0341,\n",
      "  \"parks_recreation_fitness\": 0.0268,\n",
      "  \"education\": 0.0243,\n",
      "  \"visual_performing\": 0.021,\n",
      "  \"multidiscipline\": 0.0141,\n",
      "  \"computer\": 0.0139,\n",
      "  \"public_administration_social_service\": 0.0111,\n",
      "  \"english\": 0.0105,\n",
      "  \"mathematics\": 0.0095,\n",
      "  \"physical_science\": 0.0095,\n",
      "  \"history\": 0.0087,\n",
      "  \"language\": 0.0042,\n",
      "  \"resources\": 0.0036,\n",
      "  \"philosophy_religious\": 0.0028,\n",
      "  \"ethnic_cultural_gender\": 0.0016,\n",
      "  \"legal\": 0,\n",
      "  \"library\": 0,\n",
      "  \"military\": 0,\n",
      "  \"humanities\": 0,\n",
      "  \"agriculture\": 0,\n",
      "  \"architecture\": 0,\n",
      "  \"construction\": 0,\n",
      "  \"transportation\": 0,\n",
      "  \"personal_culinary\": 0,\n",
      "  \"science_technology\": 0,\n",
      "  \"precision_production\": 0,\n",
      "  \"engineering_technology\": 0,\n",
      "  \"security_law_enforcement\": 0,\n",
      "  \"communications_technology\": 0,\n",
      "  \"mechanic_repair_technology\": 0,\n",
      "  \"theology_religious_vocation\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Store the key\n",
    "key=$(cat apiKey.txt)\n",
    "\n",
    "# Set the condition and url encode it\n",
    "condition='school.name=The%20University%20of%20Alabama'\n",
    "\n",
    "# Store the url\n",
    "url=\"http://api.data.gov/ed/collegescorecard/v1/schools?${condition}&api_key=${key}\"\n",
    "\n",
    "# Call the API and retrieve the metadata\n",
    "api_data=$(./college_score -url \"$url\" | jq '.[\"results\"][0][\"latest\"][\"academics\"][\"program_percentage\"]')\n",
    "\n",
    "# Sort the data by the value\n",
    "sorted_data=$(echo \"$api_data\" | jq 'to_entries | sort_by(-.value) | from_entries')\n",
    "\n",
    "# Print results\n",
    "echo \"$sorted_data\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
