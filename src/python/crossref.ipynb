{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossref API in Python\n",
    "\n",
    "By Avery Fernandez and Vincent F. Scalfani\n",
    "\n",
    "The Crossref API provides metadata about publications, including articles, books, and conference proceedings. This metadata spans items such as author details, journal details, references, and DOIs (Digital Object Identifiers). Working with Crossref allows for programmatic access to bibliographic information and can streamline large-scale metadata retrieval.\n",
    "\n",
    "Please see the following resources for more information on API usage:\n",
    "- Documentation\n",
    "    - <a href=\"https://api.crossref.org/swagger-ui/index.html\" target=\"_blank\">Crossref API Documentation</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/a-non-technical-introduction-to-our-api/\" target=\"_blank\">Crossref API Introduction</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/text-and-data-mining/\" target=\"_blank\">Crossref Data Mining</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/text-and-data-mining-for-members/\" target=\"_blank\">Crossref Data Mining for Members</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/text-and-data-mining-for-researchers/\" target=\"_blank\">Crossref Data Mining for Researchers</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/providing-full-text-links-to-tdm-tools/\" target=\"_blank\">Crossref Full-Text Links</a>\n",
    "- Terms\n",
    "    - <a href=\"https://www.crossref.org/membership/terms/\" target=\"_blank\">Crossref Terms of Use</a>\n",
    "- Data Reuse\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/rest-api-metadata-license-information/\" target=\"_blank\">Crossref Metadata Reuse</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/providing-licensing-information-to-tdm-tools/\" target=\"_blank\">Crossref TDM Licensing</a>\n",
    "\n",
    "**_NOTE:_** The <a href=\"https://api.crossref.org/swagger-ui/index.html\" target=\"_blank\">Crossref API</a> limits requests to a maximum of 50 per second.\n",
    "\n",
    "*These recipe examples were tested on April 18, 2025.*\n",
    "\n",
    "_**Note:**_ From our testing, we have found that the Crossref metadata across publishers and even journals can vary considerably. As a result, it can be easier to work with one journal at a time when using the Crossref API (particularly when trying to extract selected data from records)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The following external libraries need to be installed into your enviornment to run the code examples in this tutorial:\n",
    "* <a href=\"https://github.com/psf/requests\" target=\"_blank\">requests</a>\n",
    "* <a href=\"https://github.com/theskumar/python-dotenv\" target=\"_blank\">python-dotenv</a>\n",
    "* <a href=\"https://github.com/ipython/ipykernel\" target=\"_blank\">ipykernel</a>\n",
    "\n",
    "We import the libraries used in this tutorial below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175faca0",
   "metadata": {},
   "source": [
    "### Import Email\n",
    "\n",
    "It is important to provide an email address when making requests to the Crossref API. This is used to contact you in case of any issues with your requests.\n",
    "\n",
    "We keep our email in a separate file, a `.env` file, and use the `dotenv` library to access it. If you use this method, create a file named `.env` in the same directory as this notebook and add the following line to it:\n",
    "\n",
    "```text\n",
    "CROSSREF_EMAIL=PUT_YOUR_EMAIL_HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e9c3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and email successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "try:\n",
    "    email = os.environ['CROSSREF_EMAIL']\n",
    "except KeyError:\n",
    "    print(\"Email not found in environment. Please set CROSSREF_EMAIL in your .env file.\")\n",
    "else:\n",
    "    print(\"Environment and email successfully loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Crossref API Call\n",
    "\n",
    "In this section, we perform a basic API call to the Crossref service to retrieve metadata for a single DOI.\n",
    "\n",
    "We will:\n",
    "1. Build the Crossref endpoint using our base URL, DOI, and the `mailto` parameter.\n",
    "2. Retrieve the response.\n",
    "3. Examine and parse the JSON data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for Crossref works\n",
    "base_url = \"https://api.crossref.org/works/\" \n",
    "# Example DOI to retrieve metadata for\n",
    "doi = \"10.1186/1758-2946-4-12\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{base_url}{doi}?mailto={email}\")\n",
    "    response.raise_for_status()  # Raises an HTTPError if an unsuccessful status code\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print({\"error\": f\"Request failed: {str(e)}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7aea4",
   "metadata": {},
   "source": [
    "This calls the Crossref API to retrieve metadata for a single DOI, but the data is in a JSON format. We can extract the information we need from the call using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a76557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    api_data = response.json()\n",
    "    print(api_data['status'])\n",
    "except json.JSONDecodeError as e:\n",
    "    print({\"error\": f\"Failed to decode JSON: {str(e)}\"})\n",
    "    api_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Some Specific Data\n",
    "\n",
    "In the snippet below, we parse and extract some key fields from the response:\n",
    "1. **Journal title** via the `container-title` key.\n",
    "2. **Article title** via the `title` key.\n",
    "3. **Author names** via the `author` key.\n",
    "4. **Bibliographic references** via the `reference` key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journal Title: ['Journal of Cheminformatics']\n",
      "Article Title: ['The Molecule Cloud - compact visualization of large collections of molecules']\n",
      "\n",
      "Authors:\n",
      " - Peter Ertl\n",
      " - Bernhard Rohde\n",
      "\n",
      "Bibliography References (first 5):\n",
      "['Martin E, Ertl P, Hunt P, Duca J, Lewis R: Gazing into the crystal ball; the '\n",
      " 'future of computer-aided drug design. J Comp-Aided Mol Des. 2011, 26: 77-79.',\n",
      " 'Langdon SR, Brown N, Blagg J: Scaffold diversity of exemplified medicinal '\n",
      " 'chemistry space. J Chem Inf Model. 2011, 26: 2174-2185.',\n",
      " 'Blum LC, Reymond J-C: 970 Million druglike small molecules for virtual '\n",
      " 'screening in the chemical universe database GDB-13. J Am Chem Soc. 2009, '\n",
      " '131: 8732-8733. 10.1021/ja902302h.',\n",
      " 'Dubois J, Bourg S, Vrain C, Morin-Allory L: Collections of compounds - how '\n",
      " 'to deal with them?. Cur Comp-Aided Drug Des. 2008, 4: 156-168. '\n",
      " '10.2174/157340908785747410.',\n",
      " 'Medina-Franco JL, Martinez-Mayorga K, Giulianotti MA, Houghten RA, Pinilla '\n",
      " 'C: Visualization of the chemical space in drug discovery. Cur Comp-Aided '\n",
      " 'Drug Des. 2008, 4: 322-333. 10.2174/157340908786786010.']\n"
     ]
    }
   ],
   "source": [
    "if api_data:\n",
    "    # Extract Journal title\n",
    "    try:\n",
    "        journal_title = api_data[\"message\"].get(\"container-title\", [\"Not available\"])\n",
    "        print(\"Journal Title:\", journal_title)\n",
    "    except KeyError:\n",
    "        print(\"Error: 'container-title' not found in response.\")\n",
    "\n",
    "    # Extract Article title\n",
    "    try:\n",
    "        article_title = api_data[\"message\"].get(\"title\", [\"Not available\"])\n",
    "        print(\"Article Title:\", article_title)\n",
    "    except KeyError:\n",
    "        print(\"Error: 'title' not found in response.\")\n",
    "\n",
    "    # Extract Author Names\n",
    "    print(\"\\nAuthors:\")\n",
    "    try:\n",
    "        authors = api_data[\"message\"].get(\"author\", [])\n",
    "        for au in authors:\n",
    "            given = au.get(\"given\", \"\")\n",
    "            family = au.get(\"family\", \"\")\n",
    "            print(f\" - {given} {family}\")\n",
    "    except KeyError:\n",
    "        print(\"Error: 'author' not found in response.\")\n",
    "\n",
    "    # Extract Bibliography References\n",
    "    print(\"\\nBibliography References (first 5):\")\n",
    "    bib_refs = []\n",
    "    try:\n",
    "        references = api_data[\"message\"].get(\"reference\", [])\n",
    "        for ref in references:\n",
    "            bib_refs.append(ref.get(\"unstructured\", \"\"))\n",
    "        pprint(bib_refs[:5])\n",
    "    except KeyError:\n",
    "        print(\"Error: 'reference' not found in response.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load JSON Data\n",
    "\n",
    "It can be handy to store the response to a file so that you do not need to call the API again for the same metadata.\n",
    "Below, we show how to save the JSON data and load it back from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved JSON data to 'my_data.json'.\n",
      "Successfully loaded JSON data from 'my_data.json'.\n",
      "['The Molecule Cloud - compact visualization of large collections of molecules']\n"
     ]
    }
   ],
   "source": [
    "# Save JSON data to a file\n",
    "try:\n",
    "    with open('my_data.json', 'w') as outfile:\n",
    "        json.dump(api_data, outfile)\n",
    "    print(\"Successfully saved JSON data to 'my_data.json'.\")\n",
    "except IOError as e:\n",
    "    print(f\"Error saving to file: {str(e)}\")\n",
    "\n",
    "# Load JSON data from a file\n",
    "try:\n",
    "    with open('my_data.json','r') as infile:\n",
    "        loaded_data = json.load(infile)\n",
    "    print(\"Successfully loaded JSON data from 'my_data.json'.\")\n",
    "    # Optionally, verify a field\n",
    "    pprint(loaded_data.get(\"message\", {}).get(\"title\", \"Not found\"))\n",
    "except IOError as e:\n",
    "    print(f\"Error loading from file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crossref API Call with a Loop\n",
    "\n",
    "In this section, we want to request metadata from multiple DOIs at once. We will:\n",
    "1. Create a list of several DOIs.\n",
    "2. Loop through that list, calling the Crossref API for each DOI.\n",
    "3. Store each response in a new list.\n",
    "4. Parse specific data, such as article titles and affiliations.\n",
    "\n",
    "> **Note**: We include a one-second sleep (`time.sleep(1)`) between requests to respect Crossref's <a href=\"https://api.crossref.org/swagger-ui/index.html\" target=\"_blank\">policies</a>. Crossref has usage guidelines that discourage extremely rapid repeated requests. Please also check out Crossref's <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/tips-for-using-public-data-files-and-plus-snapshots/\" target=\"_blank\">public data file</a> for bulk downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Titles:\n",
      "\n",
      "Navigating into the Chemical Space of Monoamine Oxidase Inhibitors by Artificial Intelligence and Cheminformatics Approach\n",
      "Impact of Artificial Intelligence on Compound Discovery, Design, and Synthesis\n",
      "How Precise Are Our Quantitative Structure–Activity Relationship Derived Predictions for New Query Chemicals?\n",
      "Applying Neuromorphic Computing Simulation in Band Gap Prediction and Chemical Reaction Classification\n",
      "QSPR Modeling of the Refractive Index for Diverse Polymers Using 2D Descriptors\n",
      "\n",
      "Author Affiliations:\n",
      "\n",
      "DOI 1:\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      " - Department of Pharmaceutics and Industrial Pharmacy, College of Pharmacy, Taif University, P.O. Box 11099, Taif 21944, Saudi Arabia\n",
      " - Department of Pharmaceutical Chemistry, College of Pharmacy, Jouf University, Sakaka, Al Jouf 72341, Saudi Arabia\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      "\n",
      "DOI 2:\n",
      " - Department of Life Science Informatics and Data Science, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Friedrich-Hirzebruch-Allee 6, D-53115 Bonn, Germany\n",
      " - Department of Life Science Informatics and Data Science, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Friedrich-Hirzebruch-Allee 6, D-53115 Bonn, Germany\n",
      " - Department of Life Science Informatics and Data Science, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Friedrich-Hirzebruch-Allee 6, D-53115 Bonn, Germany\n",
      "\n",
      "DOI 3:\n",
      " - Drug Theoretics and Cheminformatics Laboratory, Department of Pharmaceutical Technology, Jadavpur University, Kolkata 700 032, India\n",
      " - Drug Theoretics and Cheminformatics Laboratory, Department of Pharmaceutical Technology, Jadavpur University, Kolkata 700 032, India\n",
      " - Interdisciplinary Center for Nanotoxicity, Department of Chemistry, Physics and Atmospheric Sciences, Jackson State University, Jackson, Mississippi 39217, United States\n",
      "\n",
      "DOI 4:\n",
      " - Department of Chemical and Biomolecular Engineering, The Ohio State University, Columbus, Ohio 43210, United States\n",
      " - Department of Chemical and Biomolecular Engineering, The Ohio State University, Columbus, Ohio 43210, United States\n",
      " - Department of Chemical and Biomolecular Engineering, The Ohio State University, Columbus, Ohio 43210, United States\n",
      " - Department of Chemical and Biomolecular Engineering, The Ohio State University, Columbus, Ohio 43210, United States\n",
      "\n",
      "DOI 5:\n",
      " - Department of Pharmacoinformatics, National Institute of Pharmaceutical Educational and Research (NIPER), Chunilal Bhawan, 168, Manikata Main Road, 700054 Kolkata, India\n",
      " - Department of Coatings and Polymeric Materials, North Dakota State University, Fargo, North Dakota 58108-6050, United States\n",
      " - Drug Theoretics and Cheminformatics Laboratory, Division of Medicinal and Pharmaceutical Chemistry, Department of Pharmaceutical Technology, Jadavpur University, 700032 Kolkata, India\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doi_list = [\n",
    "    '10.1021/acsomega.1c03250',\n",
    "    '10.1021/acsomega.1c05512',\n",
    "    '10.1021/acsomega.8b01647',\n",
    "    '10.1021/acsomega.1c04287',\n",
    "    '10.1021/acsomega.8b01834'\n",
    "]\n",
    "\n",
    "doi_metadata = []\n",
    "# Loop over each DOI, request metadata, and store the data\n",
    "for d in doi_list:\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}{d}?mailto={email}\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        doi_metadata.append(data)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print({\"error\": f\"Request failed for DOI {d}: {str(e)}\"})\n",
    "    except json.JSONDecodeError as e:\n",
    "        print({\"error\": f\"Failed to decode JSON for DOI {d}: {str(e)}\"})\n",
    "    # Adding a short delay to avoid overwhelming the API\n",
    "    sleep(1)\n",
    "\n",
    "# Extract article titles\n",
    "print(\"Article Titles:\\n\")\n",
    "for item in doi_metadata:\n",
    "    title = item.get(\"message\", {}).get(\"title\", [\"No Title\"])[0]\n",
    "    print(title)\n",
    "\n",
    "# Extract author affiliations for each article\n",
    "print(\"\\nAuthor Affiliations:\\n\")\n",
    "for idx, entry in enumerate(doi_metadata):\n",
    "    authors = entry.get(\"message\", {}).get(\"author\", [])\n",
    "    print(f\"DOI {idx + 1}:\")\n",
    "    for au in authors:\n",
    "        # Some authors may not have an affiliation key, so we use get with a default\n",
    "        affiliation_list = au.get(\"affiliation\", [])\n",
    "        if affiliation_list:\n",
    "            print(\" -\", affiliation_list[0].get(\"name\", \"No affiliation name\"))\n",
    "        else:\n",
    "            print(\" - No affiliation provided\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieve Journal Information\n",
    "\n",
    "Crossref also provides an endpoint to query journal metadata using the **ISSN**. In this section, we:\n",
    "1. Use the `journals` endpoint.\n",
    "2. Provide an ISSN.\n",
    "3. Inspect the returned JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Base URL for journal queries\n",
    "jbase_url = \"https://api.crossref.org/journals/\"\n",
    "# Example ISSN for the journal BMC Bioinformatics\n",
    "issn = \"1471-2105\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{jbase_url}{issn}?mailto={email}\")\n",
    "    response.raise_for_status()\n",
    "    jour_data = response.json()\n",
    "    print(jour_data['status'])\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print({\"error\": f\"Request failed: {str(e)}\"})\n",
    "except json.JSONDecodeError as e:\n",
    "    print({\"error\": f\"Failed to decode JSON: {str(e)}\"})\n",
    "    jour_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Article DOIs for a Journal\n",
    "\n",
    "We can get all article DOIs for a given journal and year range by combining the **journals** endpoint with **filters**.\n",
    "For example, to retrieve all DOIs for BMC Bioinformatics published in **2014**, we filter between the start date (`from-pub-date`) and end date (`until-pub-date`) of 2014.\n",
    "\n",
    "> **Note**: By default, the API only returns the first 20 results. We can specify `rows` to increase this up to **1000**. If the total number of results is **greater** than 1000, we can use the `offset` parameter to page through the results in multiple calls.\n",
    "\n",
    "Below, we demonstrate:\n",
    "1. Filtering to get only DOIs from 2014.\n",
    "2. Increasing the `rows` to 700.\n",
    "3. Pushing beyond the 1000-row limit by using `offset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and Display First 20 DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': {'facets': {},\n",
      "             'items': [{'DOI': '10.1186/1471-2105-15-s10-p32'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-s6-s3'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-s16-s13'},\n",
      "                       {'DOI': '10.1186/s12859-014-0411-1'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-s10-p24'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-318'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-s4-s1'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-s11-i1'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-230'},\n",
      "                       {'DOI': '10.1186/s12859-014-0376-0'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-192'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-s14-s1'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-s10-p33'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-122'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-105'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-s10-p6'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-101'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-s10-p35'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-61'},\n",
      "                       {'DOI': '10.1186/1471-2105-15-24'}],\n",
      "             'items-per-page': 20,\n",
      "             'query': {'search-terms': None, 'start-index': 0},\n",
      "             'total-results': 619},\n",
      " 'message-type': 'work-list',\n",
      " 'message-version': '1.0.0',\n",
      " 'status': 'ok'}\n",
      "\n",
      "The default is 20 results.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # We will use params to make the query string more readable\n",
    "    params = {\n",
    "        \"filter\": \"from-pub-date:2014,until-pub-date:2014\",\n",
    "        \"select\": \"DOI\",\n",
    "        \"mailto\": email\n",
    "    }\n",
    "    response = requests.get(f\"{jbase_url}{issn}/works\",params=params)\n",
    "    response.raise_for_status()\n",
    "    doi_data_2014 = response.json()\n",
    "    pprint(doi_data_2014)\n",
    "    print(\"\\nThe default is 20 results.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print({\"error\": f\"Request failed: {str(e)}\"})\n",
    "except json.JSONDecodeError as e:\n",
    "    print({\"error\": f\"Failed to decode JSON: {str(e)}\"})\n",
    "    doi_data_2014 = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Rows to Retrieve More Than 20 DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of DOIs retrieved: 619\n",
      "First 20 DOIs:\n",
      "['10.1186/1471-2105-15-s10-p32',\n",
      " '10.1186/1471-2105-15-s6-s3',\n",
      " '10.1186/1471-2105-15-s16-s13',\n",
      " '10.1186/s12859-014-0411-1',\n",
      " '10.1186/1471-2105-15-s10-p24',\n",
      " '10.1186/1471-2105-15-318',\n",
      " '10.1186/1471-2105-15-s4-s1',\n",
      " '10.1186/1471-2105-15-s11-i1',\n",
      " '10.1186/1471-2105-15-230',\n",
      " '10.1186/s12859-014-0376-0',\n",
      " '10.1186/1471-2105-15-192',\n",
      " '10.1186/1471-2105-15-s14-s1',\n",
      " '10.1186/1471-2105-15-s10-p33',\n",
      " '10.1186/1471-2105-15-122',\n",
      " '10.1186/1471-2105-15-105',\n",
      " '10.1186/1471-2105-15-s10-p6',\n",
      " '10.1186/s12859-014-0397-8',\n",
      " '10.1186/1471-2105-15-s10-p35',\n",
      " '10.1186/1471-2105-15-61',\n",
      " '10.1186/1471-2105-15-24']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Add the rows parameter to increase the number of results\n",
    "    params = {\n",
    "        \"filter\": \"from-pub-date:2014,until-pub-date:2014\",\n",
    "        \"select\": \"DOI\",\n",
    "        \"rows\": 700,\n",
    "        \"mailto\": email,\n",
    "    }\n",
    "    response = requests.get(f\"{jbase_url}{issn}/works\", params=params)\n",
    "    response.raise_for_status()\n",
    "    doi_data_all = response.json()\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print({\"error\": f\"Request failed: {str(e)}\"})\n",
    "except json.JSONDecodeError as e:\n",
    "    print({\"error\": f\"Failed to decode JSON: {str(e)}\"})\n",
    "    doi_data_all = {}\n",
    "\n",
    "# Extract the DOIs from the response\n",
    "dois_list = []\n",
    "if \"message\" in doi_data_all and \"items\" in doi_data_all[\"message\"]:\n",
    "    for item in doi_data_all[\"message\"][\"items\"]:\n",
    "        dois_list.append(item.get(\"DOI\", \"NoDOI\"))\n",
    "\n",
    "print(\"Number of DOIs retrieved:\", len(dois_list))\n",
    "print(\"First 20 DOIs:\")\n",
    "pprint(dois_list[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paged Retrieval with Offsets\n",
    "\n",
    "If we need more than 1000 records, we can combine `rows=1000` with the `offset` parameter. We:\n",
    "1. Determine the total number of results (`total-results`).\n",
    "2. Calculate how many loops we need based on 1000 items per page.\n",
    "3. For each page, we adjust the `offset` by `1000 * n`.\n",
    "4. Collect all DOIs into one large list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results for 2014-2016: 1772\n",
      "\n",
      "Total DOIs gathered: 1772\n",
      "Sample DOIs from 1000-1020:\n",
      "['10.1186/s12859-016-1224-1',\n",
      " '10.1186/s12859-016-1113-7',\n",
      " '10.1186/s12859-016-1363-4',\n",
      " '10.1186/s12859-015-0861-0',\n",
      " '10.1186/s12859-016-1011-z',\n",
      " '10.1186/1471-2105-15-77',\n",
      " '10.1186/1471-2105-15-322',\n",
      " '10.1186/s12859-015-0636-7',\n",
      " '10.1186/1471-2105-16-s3-a4',\n",
      " '10.1186/1471-2105-15-334',\n",
      " '10.1186/s12859-014-0428-5',\n",
      " '10.1186/1471-2105-15-114',\n",
      " '10.1186/1471-2105-15-332',\n",
      " '10.1186/1471-2105-15-237',\n",
      " '10.1186/s12859-015-0644-7',\n",
      " '10.1186/s12859-016-1120-8',\n",
      " '10.1186/s12859-015-0526-z',\n",
      " '10.1186/s12859-016-1164-9',\n",
      " '10.1186/s12859-016-1012-y',\n",
      " '10.1186/1471-2105-15-291']\n"
     ]
    }
   ],
   "source": [
    "# First, get total number of results to see if we exceed 1000.\n",
    "try:\n",
    "    params = {\n",
    "        \"filter\": \"from-pub-date:2014,until-pub-date:2016\",\n",
    "        \"select\": \"DOI\",\n",
    "        \"mailto\": email,\n",
    "        \"rows\": 1000\n",
    "    }\n",
    "    response = requests.get(f\"{jbase_url}{issn}/works\", params=params)\n",
    "    response.raise_for_status()\n",
    "    initial_data = response.json()\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print({\"error\": f\"Request failed: {str(e)}\"})\n",
    "except json.JSONDecodeError as e:\n",
    "    print({\"error\": f\"Failed to decode JSON: {str(e)}\"})\n",
    "    initial_data = {}\n",
    "\n",
    "num_results = 0\n",
    "try:\n",
    "    num_results = initial_data[\"message\"].get(\"total-results\", 0)\n",
    "except (KeyError, TypeError):\n",
    "    print(\"Could not retrieve total-results from the initial response.\")\n",
    "    num_results = 0\n",
    "\n",
    "print(\"Total results for 2014-2016:\", num_results)\n",
    "\n",
    "# Page through results if more than 1000\n",
    "doi_list2 = []\n",
    "# Calculate how many pages we might need\n",
    "pages_needed = (num_results // 1000) + 1  # integer division, then add 1 for remainder\n",
    "\n",
    "for n in range(pages_needed):\n",
    "    try:\n",
    "        # Build URL using offset\n",
    "        params = {\n",
    "            \"filter\": \"from-pub-date:2014,until-pub-date:2016\",\n",
    "            \"select\": \"DOI\",\n",
    "            \"rows\": 1000,\n",
    "            \"mailto\": email,\n",
    "            \"offset\": 1000 * n\n",
    "        }\n",
    "        response = requests.get(f\"{jbase_url}{issn}/works\", params=params)\n",
    "        response.raise_for_status()\n",
    "        page_data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print({\"error\": f\"Request failed: {str(e)}\"})\n",
    "        continue    \n",
    "    # If there's an error or no \"message\" key, we skip.\n",
    "    if \"message\" not in page_data or \"items\" not in page_data[\"message\"]:\n",
    "        continue\n",
    "\n",
    "    items = page_data[\"message\"][\"items\"]\n",
    "    for record in items:\n",
    "        doi_list2.append(record.get(\"DOI\", \"NoDOI\"))\n",
    "        \n",
    "    # Important to respect Crossref usage guidelines\n",
    "    sleep(1)\n",
    "\n",
    "print(f\"\\nTotal DOIs gathered: {len(doi_list2)}\")\n",
    "print(\"Sample DOIs from 1000-1020:\")\n",
    "pprint(doi_list2[1000:1020])"
   ]
  }
 ],
 "metadata": {
  "cells": [],
  "kernelspec": {
   "display_name": "api_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
