{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossref API in Python\n",
    "\n",
    "By Avery Fernandez, Vincent F. Scalfani, and Michael T. Moen\n",
    "\n",
    "The Crossref API provides metadata about publications, including articles, books, and conference proceedings. This metadata spans items such as author details, journal details, references, and DOIs (Digital Object Identifiers). Working with Crossref allows for programmatic access to bibliographic information and can streamline large-scale metadata retrieval.\n",
    "\n",
    "Please see the following resources for more information on API usage:\n",
    "- Documentation\n",
    "    - <a href=\"https://api.crossref.org/swagger-ui/index.html\" target=\"_blank\">Crossref API Documentation</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/a-non-technical-introduction-to-our-api/\" target=\"_blank\">Crossref API Introduction</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/text-and-data-mining/\" target=\"_blank\">Crossref Data Mining</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/text-and-data-mining-for-members/\" target=\"_blank\">Crossref Data Mining for Members</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/text-and-data-mining-for-researchers/\" target=\"_blank\">Crossref Data Mining for Researchers</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/providing-full-text-links-to-tdm-tools/\" target=\"_blank\">Crossref Full-Text Links</a>\n",
    "- Terms\n",
    "    - <a href=\"https://www.crossref.org/membership/terms/\" target=\"_blank\">Crossref Terms of Use</a>\n",
    "- Data Reuse\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/rest-api-metadata-license-information/\" target=\"_blank\">Crossref Metadata Reuse</a>\n",
    "    - <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/providing-licensing-information-to-tdm-tools/\" target=\"_blank\">Crossref TDM Licensing</a>\n",
    "\n",
    "**_NOTE:_** The <a href=\"https://api.crossref.org/swagger-ui/index.html\" target=\"_blank\">Crossref API</a> limits requests to a maximum of 50 per second.\n",
    "\n",
    "*These recipe examples were tested on January 28, 2026.*\n",
    "\n",
    "_**Note:**_ From our testing, we have found that the Crossref metadata across publishers and even journals can vary considerably. As a result, it can be easier to work with one journal at a time when using the Crossref API (particularly when trying to extract selected data from records)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The following external libraries need to be installed into your environment to run the code examples in this tutorial:\n",
    "- <a href=\"https://github.com/ipython/ipykernel\" target=\"_blank\">ipykernel</a>\n",
    "- <a href=\"https://github.com/theskumar/python-dotenv\" target=\"_blank\">python-dotenv</a>\n",
    "- <a href=\"https://github.com/psf/requests\" target=\"_blank\">requests</a>\n",
    "\n",
    "We import the libraries used in this tutorial below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175faca0",
   "metadata": {},
   "source": [
    "### Import Email\n",
    "\n",
    "It is important to provide an email address when making requests to the Crossref API. This is used to contact you in case of any issues with your requests.\n",
    "\n",
    "We keep our email in a separate file, a `.env` file, and use the `dotenv` library to access it. If you use this method, create a file named `.env` in the same directory as this notebook and add the following line to it:\n",
    "\n",
    "```text\n",
    "CROSSREF_EMAIL=PUT_YOUR_EMAIL_HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e9c3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and email successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "try:\n",
    "    email = os.environ['CROSSREF_EMAIL']\n",
    "except KeyError:\n",
    "    print(\"Email not found in environment. Please set CROSSREF_EMAIL in your .env file.\")\n",
    "else:\n",
    "    print(\"Environment and email successfully loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Crossref API Call\n",
    "\n",
    "In this section, we perform a basic API call to the Crossref service to retrieve metadata for a single DOI.\n",
    "\n",
    "We will:\n",
    "1. Build the Crossref endpoint using our base URL, DOI, and the `mailto` parameter.\n",
    "2. Retrieve the response.\n",
    "3. Examine and parse the JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base URL for Crossref works\n",
    "WORKS_URL = \"https://api.crossref.org/works/\"\n",
    "\n",
    "# Example DOI to retrieve metadata for\n",
    "doi = \"10.1186/1758-2946-4-12\"\n",
    "\n",
    "response = requests.get(f\"{WORKS_URL}{doi}?mailto={email}\")\n",
    "\n",
    "# Status code 200 indicates success\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7aea4",
   "metadata": {},
   "source": [
    "This calls the Crossref API to retrieve metadata for a single DOI, but the data is in a JSON format. We can extract the information we need from the call using `.json()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a76557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': {...},\n",
      " 'message-type': 'work',\n",
      " 'message-version': '1.0.0',\n",
      " 'status': 'ok'}\n"
     ]
    }
   ],
   "source": [
    "data = response.json()\n",
    "\n",
    "# Print response structure\n",
    "pprint(data, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data from API Response\n",
    "\n",
    "In the snippet below, we parse and extract some key fields from the response:\n",
    "1. **Journal title** via the `container-title` key.\n",
    "2. **Article title** via the `title` key.\n",
    "3. **Author names** via the `author` key.\n",
    "4. **Bibliographic references** via the `reference` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b5861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Journal of Cheminformatics']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract journal title\n",
    "data[\"message\"][\"container-title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0da8f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Molecule Cloud - compact visualization of large collections of molecules']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract article title\n",
    "data[\"message\"][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75d43b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter Ertl\n",
      "Bernhard Rohde\n"
     ]
    }
   ],
   "source": [
    "# Extract author names\n",
    "for author in data[\"message\"][\"author\"]:\n",
    "    print(f\"{author[\"given\"]} {author[\"family\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Martin E, Ertl P, Hunt P, Duca J, Lewis R: Gazing into the crystal ball; th',\n",
       " 'Langdon SR, Brown N, Blagg J: Scaffold diversity of exemplified medicinal c',\n",
       " 'Blum LC, Reymond J-C: 970 Million druglike small molecules for virtual scre',\n",
       " 'Dubois J, Bourg S, Vrain C, Morin-Allory L: Collections of compounds - how ',\n",
       " 'Medina-Franco JL, Martinez-Mayorga K, Giulianotti MA, Houghten RA, Pinilla ',\n",
       " 'Schuffenhauer A, Ertl P, Roggo S, Wetzel S, Koch MA, Waldmann H: The Scaffo',\n",
       " 'Langdon S, Ertl P, Brown N: Bioisosteric replacement and scaffold hopping i',\n",
       " 'Lipkus AH, Yuan Q, Lucas KA, Funk SA, Bartelt WF, Schenck RJ, Trippe AJ: St',\n",
       " 'mib 2010.10, Molinspiration Cheminformatics: \\n                    http://ww',\n",
       " 'Bernhard R: Avalon Cheminformatics Toolkit. \\n                    http://sou',\n",
       " 'Wang Y, Bolton E, Dracheva S, Karapetyan K, Shoemaker BA, Suzek TO, Wang J,',\n",
       " 'Irwin JJ, Shoichet BK: ZINC\\u2009−\\u2009a free database of commercially available com',\n",
       " 'Gaulton A, Bellis LJ, Bento AP, Chambers J, Davies M, Hersey A, Light Y, Mc',\n",
       " 'Welsch ME, Snyder SA, Stockwell BR: Privileged scaffolds for library design',\n",
       " 'Ertl P: Cheminformatics analysis of organic substituents: Identification of',\n",
       " 'TagCrowd: \\n                    http://tagcrowd.com']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first 75 characters of each reference for demonstration\n",
    "bib_refs = [ref[\"unstructured\"][:75] for ref in data[\"message\"][\"reference\"]]\n",
    "bib_refs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crossref API Call with a Loop\n",
    "\n",
    "In this section, we want to request metadata from multiple DOIs at once. We will:\n",
    "1. Create a list of several DOIs.\n",
    "2. Loop through that list, calling the Crossref API for each DOI.\n",
    "3. Store each response in a new list.\n",
    "4. Parse specific data, such as article titles and affiliations.\n",
    "\n",
    "> **Note**: We include a one-second sleep (`time.sleep(1)`) between requests to respect Crossref's <a href=\"https://api.crossref.org/swagger-ui/index.html\" target=\"_blank\">policies</a>. Crossref has usage guidelines that discourage extremely rapid repeated requests. Please also check out Crossref's <a href=\"https://www.crossref.org/documentation/retrieve-metadata/rest-api/tips-for-using-public-data-files-and-plus-snapshots/\" target=\"_blank\">public data file</a> for bulk downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois = [\n",
    "    '10.1021/acsomega.1c03250',\n",
    "    '10.1021/acsomega.1c05512',\n",
    "    '10.1021/acsomega.8b01647',\n",
    "    '10.1021/acsomega.1c04287',\n",
    "    '10.1021/acsomega.8b01834'\n",
    "]\n",
    "\n",
    "# Loop over each DOI, request metadata, and store the data\n",
    "doi_metadata = []\n",
    "for doi in dois:\n",
    "    response = requests.get(f\"{WORKS_URL}{doi}?mailto={email}\")\n",
    "    data = response.json()\n",
    "    doi_metadata.append(data)\n",
    "    sleep(1)    # Add a short delay to avoid overwhelming the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb9181e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Navigating into the Chemical Space of Monoamine Oxidase Inhibitors by Artificial Intelligence and Cheminformatics Approach'],\n",
       " ['Impact of Artificial Intelligence on Compound Discovery, Design, and Synthesis'],\n",
       " ['How Precise Are Our Quantitative Structure–Activity Relationship Derived Predictions for New Query Chemicals?'],\n",
       " ['Applying Neuromorphic Computing Simulation in Band Gap Prediction and Chemical Reaction Classification'],\n",
       " ['QSPR Modeling of the Refractive Index for Diverse Polymers Using 2D Descriptors']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract article titles\n",
    "titles = [article[\"message\"][\"title\"] for article in doi_metadata]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f13d778",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI 1:\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      " - Department of Pharmaceutics and Industrial Pharmacy, College of Pharmacy, Taif University, P.O. Box 11099, Taif 21944, Saudi Arabia\n",
      " - Department of Pharmaceutical Chemistry, College of Pharmacy, Jouf University, Sakaka, Al Jouf 72341, Saudi Arabia\n",
      " - Department of Pharmaceutical Chemistry and Analysis, Amrita School of Pharmacy, Amrita Vishwa Vidyapeetham, AIMS Health Sciences Campus, Kochi 682041, India\n",
      "\n",
      "DOI 2:\n",
      " - Department of Life Science Informatics and Data Science, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Friedrich-Hirzebruch-Allee 6, D-53115 Bonn, Germany\n",
      " - Department of Life Science Informatics and Data Science, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Friedrich-Hirzebruch-Allee 6, D-53115 Bonn, Germany\n",
      " - Department of Life Science Informatics and Data Science, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Friedrich-Hirzebruch-Allee 6, D-53115 Bonn, Germany\n",
      "\n",
      "DOI 3:\n",
      " - Drug Theoretics and Cheminformatics Laboratory, Department of Pharmaceutical Technology, Jadavpur University, Kolkata 700 032, India\n",
      " - Drug Theoretics and Cheminformatics Laboratory, Department of Pharmaceutical Technology, Jadavpur University, Kolkata 700 032, India\n",
      " - Interdisciplinary Center for Nanotoxicity, Department of Chemistry, Physics and Atmospheric Sciences, Jackson State University, Jackson, Mississippi 39217, United States\n",
      "\n",
      "DOI 4:\n",
      " - Department of Chemical and Biomolecular Engineering, The Ohio State University, Columbus, Ohio 43210, United States\n",
      " - Department of Chemical and Biomolecular Engineering, The Ohio State University, Columbus, Ohio 43210, United States\n",
      " - Department of Chemical and Biomolecular Engineering, The Ohio State University, Columbus, Ohio 43210, United States\n",
      " - Department of Chemical and Biomolecular Engineering, The Ohio State University, Columbus, Ohio 43210, United States\n",
      "\n",
      "DOI 5:\n",
      " - Department of Pharmacoinformatics, National Institute of Pharmaceutical Educational and Research (NIPER), Chunilal Bhawan, 168, Manikata Main Road, 700054 Kolkata, India\n",
      " - Department of Coatings and Polymeric Materials, North Dakota State University, Fargo, North Dakota 58108-6050, United States\n",
      " - Drug Theoretics and Cheminformatics Laboratory, Division of Medicinal and Pharmaceutical Chemistry, Department of Pharmaceutical Technology, Jadavpur University, 700032 Kolkata, India\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract author affiliations for each article\n",
    "for idx, entry in enumerate(doi_metadata):\n",
    "    authors = entry.get(\"message\", {}).get(\"author\", [])\n",
    "    print(f\"DOI {idx + 1}:\")\n",
    "    for author in authors:\n",
    "        # Some authors may not have an affiliation key, so we use get with a default\n",
    "        affiliation_list = author.get(\"affiliation\", [])\n",
    "        if affiliation_list:\n",
    "            print(f\" - {affiliation_list[0].get(\"name\", \"No affiliation name\")}\")\n",
    "        else:\n",
    "            print(\" - No affiliation provided\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieve Journal Information\n",
    "\n",
    "Crossref also provides an endpoint to query journal metadata using the **ISSN**. In this section, we:\n",
    "1. Use the `journals` endpoint.\n",
    "2. Provide an ISSN.\n",
    "3. Inspect the returned JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ISSN': [...],\n",
      " 'breakdowns': {...},\n",
      " 'counts': {...},\n",
      " 'coverage': {...},\n",
      " 'coverage-type': {...},\n",
      " 'flags': {...},\n",
      " 'issn-type': [...],\n",
      " 'last-status-check-time': 1759277629723,\n",
      " 'publisher': 'Springer (Biomed Central Ltd.)',\n",
      " 'subjects': [],\n",
      " 'title': 'BMC Bioinformatics'}\n"
     ]
    }
   ],
   "source": [
    "# Base URL for journal queries\n",
    "JOURNALS_URL = \"https://api.crossref.org/journals/\"\n",
    "\n",
    "# Example ISSN for the journal BMC Bioinformatics\n",
    "issn = \"1471-2105\"\n",
    "\n",
    "response = requests.get(f\"{JOURNALS_URL}{issn}?mailto={email}\")\n",
    "data = response.json()\n",
    "\n",
    "# Print structure of the response message\n",
    "pprint(data[\"message\"], depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5affffdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12831"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract total number of articles from the journal in Crossref\n",
    "data[\"message\"][\"counts\"][\"total-dois\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8d57a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.787422497785651"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract percentage of articles from the journal with abstracts in Crossref\n",
    "data[\"message\"][\"coverage\"][\"abstracts-current\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Article DOIs for a Journal\n",
    "\n",
    "We can get all article DOIs for a given journal and year range by combining the **journals** endpoint with **filters**.\n",
    "For example, to retrieve all DOIs for BMC Bioinformatics published in **2014**, we filter between the start date (`from-pub-date`) and end date (`until-pub-date`) of 2014.\n",
    "\n",
    "> **Note**: By default, the API only returns the first 20 results. We can specify `rows` to increase this up to **1000**. If the total number of results is **greater** than 1000, we can use the `offset` parameter to page through the results in multiple calls.\n",
    "\n",
    "Below, we demonstrate:\n",
    "1. Filtering to get only DOIs from 2014.\n",
    "2. Increasing the `rows` to 700.\n",
    "3. Pushing beyond the 1000-row limit by using `offset`.\n",
    "\n",
    "### Retrieve and Display First 20 DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'DOI': '10.1186/1471-2105-15-38'},\n",
       " {'DOI': '10.1186/1471-2105-15-s10-p35'},\n",
       " {'DOI': '10.1186/1471-2105-15-s10-p24'},\n",
       " {'DOI': '10.1186/1471-2105-15-122'},\n",
       " {'DOI': '10.1186/1471-2105-15-24'},\n",
       " {'DOI': '10.1186/s12859-014-0397-8'},\n",
       " {'DOI': '10.1186/1471-2105-15-16'},\n",
       " {'DOI': '10.1186/s12859-014-0411-1'},\n",
       " {'DOI': '10.1186/1471-2105-15-268'},\n",
       " {'DOI': '10.1186/1471-2105-15-119'},\n",
       " {'DOI': '10.1186/1471-2105-15-s6-s3'},\n",
       " {'DOI': '10.1186/1471-2105-15-310'},\n",
       " {'DOI': '10.1186/1471-2105-15-335'},\n",
       " {'DOI': '10.1186/1471-2105-15-222'},\n",
       " {'DOI': '10.1186/1471-2105-15-337'},\n",
       " {'DOI': '10.1186/1471-2105-15-95'},\n",
       " {'DOI': '10.1186/1471-2105-15-s9-s12'},\n",
       " {'DOI': '10.1186/1471-2105-15-254'},\n",
       " {'DOI': '10.1186/1471-2105-15-152'},\n",
       " {'DOI': '10.1186/1471-2105-15-333'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"filter\": \"from-pub-date:2014,until-pub-date:2014\",\n",
    "    \"select\": \"DOI\",\n",
    "    \"mailto\": email\n",
    "}\n",
    "response = requests.get(f\"{JOURNALS_URL}{issn}/works\", params=params)\n",
    "doi_data_2014 = response.json()\n",
    "\n",
    "# Print DOIs from the response\n",
    "doi_data_2014[\"message\"][\"items\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Rows to Retrieve More Than 20 DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of DOIs retrieved: 619\n",
      "First 20 DOIs:\n",
      "['10.1186/1471-2105-15-38',\n",
      " '10.1186/1471-2105-15-s10-p35',\n",
      " '10.1186/1471-2105-15-s10-p24',\n",
      " '10.1186/1471-2105-15-122',\n",
      " '10.1186/1471-2105-15-24',\n",
      " '10.1186/s12859-014-0397-8',\n",
      " '10.1186/1471-2105-15-16',\n",
      " '10.1186/s12859-014-0411-1',\n",
      " '10.1186/1471-2105-15-268',\n",
      " '10.1186/1471-2105-15-119',\n",
      " '10.1186/1471-2105-15-s6-s3',\n",
      " '10.1186/s12859-014-0376-0',\n",
      " '10.1186/1471-2105-15-310',\n",
      " '10.1186/1471-2105-15-335',\n",
      " '10.1186/1471-2105-15-192',\n",
      " '10.1186/1471-2105-15-95',\n",
      " '10.1186/1471-2105-15-s9-s12',\n",
      " '10.1186/1471-2105-15-254',\n",
      " '10.1186/1471-2105-15-152',\n",
      " '10.1186/1471-2105-15-333']\n"
     ]
    }
   ],
   "source": [
    "# Add the rows parameter to increase the number of results\n",
    "params = {\n",
    "    \"filter\": \"from-pub-date:2014,until-pub-date:2014\",\n",
    "    \"select\": \"DOI\",\n",
    "    \"rows\": 700,\n",
    "    \"mailto\": email,\n",
    "}\n",
    "response = requests.get(f\"{JOURNALS_URL}{issn}/works\", params=params)\n",
    "response.raise_for_status()\n",
    "doi_data_all = response.json()\n",
    "\n",
    "# Extract the DOIs from the response\n",
    "dois_list = []\n",
    "for item in doi_data_all[\"message\"][\"items\"]:\n",
    "    dois_list.append(item.get(\"DOI\", \"NoDOI\"))\n",
    "\n",
    "print(\"Number of DOIs retrieved:\", len(dois_list))\n",
    "print(\"First 20 DOIs:\")\n",
    "pprint(dois_list[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paged Retrieval with Offsets\n",
    "\n",
    "If we need more than 1000 records, we can combine `rows=1000` with the `offset` parameter. We:\n",
    "1. Determine the total number of results (`total-results`).\n",
    "2. Calculate how many loops we need based on 1000 items per page.\n",
    "3. For each page, we adjust the `offset` by `1000 * n`.\n",
    "4. Collect all DOIs into one large list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results for 2014-2016: 1772\n"
     ]
    }
   ],
   "source": [
    "# First, get total number of results to see if we exceed 1000\n",
    "params = {\n",
    "    \"filter\": \"from-pub-date:2014,until-pub-date:2016\",\n",
    "    \"select\": \"DOI\",\n",
    "    \"mailto\": email,\n",
    "    \"rows\": 1000\n",
    "}\n",
    "response = requests.get(f\"{JOURNALS_URL}{issn}/works\", params=params)\n",
    "initial_data = response.json()\n",
    "\n",
    "num_results = initial_data[\"message\"].get(\"total-results\", 0)\n",
    "print(\"Total results for 2014-2016:\", num_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3739369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1772"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Page through results if more than 1000\n",
    "journal_dois = []\n",
    "\n",
    "# Calculate how many pages we need\n",
    "pages_needed = (num_results // 1000) + 1  # integer division, then add 1 for remainder\n",
    "\n",
    "for n in range(pages_needed):\n",
    "    # Build URL using offset\n",
    "    params = {\n",
    "        \"filter\": \"from-pub-date:2014,until-pub-date:2016\",\n",
    "        \"select\": \"DOI\",\n",
    "        \"rows\": 1000,\n",
    "        \"mailto\": email,\n",
    "        \"offset\": 1000 * n\n",
    "    }\n",
    "    response = requests.get(f\"{JOURNALS_URL}{issn}/works\", params=params)\n",
    "    response.raise_for_status()\n",
    "    page_data = response.json()\n",
    "\n",
    "    items = page_data[\"message\"][\"items\"]\n",
    "    for record in items:\n",
    "        journal_dois.append(record.get(\"DOI\", \"NoDOI\"))\n",
    "        \n",
    "    sleep(1)    # Important to respect Crossref usage guidelines\n",
    "\n",
    "# Print number of DOIs extracted\n",
    "len(journal_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b422f18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10.1186/1471-2105-15-116',\n",
       " '10.1186/s12859-016-1178-3',\n",
       " '10.1186/1471-2105-15-s12-s9',\n",
       " '10.1186/1471-2105-15-316',\n",
       " '10.1186/s12859-016-1233-0',\n",
       " '10.1186/s12859-015-0656-3',\n",
       " '10.1186/s12859-016-1327-8',\n",
       " '10.1186/s12859-016-1039-0',\n",
       " '10.1186/s12859-016-1035-4',\n",
       " '10.1186/s12859-015-0646-5']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample DOIs from 1000-1010\n",
    "journal_dois[1000:1010]"
   ]
  }
 ],
 "metadata": {
  "cells": [],
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
