{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scopus API in Python\n",
    "\n",
    "by Vincent F. Scalfani\n",
    "\n",
    "These recipe examples use the Elsevier Scopus API and the Python Scopus API-wrapper package, [pybliometrics](https://pybliometrics.readthedocs.io/en/stable/). Code was tested and sample data downloaded from the Scopus API on February 16, 2022 via http://api.elsevier.com and http://www.scopus.com. This tutorial content is intended to help facillitate academic research. Before continuing or reusing any of this code, please be aware of Elsevier's [API policies and appropiate use-cases](https://dev.elsevier.com/use_cases.html). You will also need to register for an API key in order to use the Scopus API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Pybliometrics Setup\n",
    "\n",
    "The first time you run `import pybliometrics`, it will prompt you for your Elsevier Scopus API Key,\n",
    "which is then saved to a local config file. See the documentation:\n",
    "https://pybliometrics.readthedocs.io/en/stable/configuration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybliometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import other libraries needed\n",
    "from pybliometrics.scopus import ScopusSearch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get Author Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Records for Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scopus Author ID field (AU-ID): 55764087400, Vincent Scalfani\n",
    "q1 = ScopusSearch('AU-ID(55764087400)', download=False)\n",
    "q1.get_results_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Record Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = ScopusSearch('AU-ID(55764087400)')\n",
    "\n",
    "# save to dataframe\n",
    "df1 = pd.DataFrame(q1.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eid', 'doi', 'pii', 'pubmed_id', 'title', 'subtype',\n",
       "       'subtypeDescription', 'creator', 'afid', 'affilname',\n",
       "       'affiliation_city', 'affiliation_country', 'author_count',\n",
       "       'author_names', 'author_ids', 'author_afids', 'coverDate',\n",
       "       'coverDisplayDate', 'publicationName', 'issn', 'source_id', 'eIssn',\n",
       "       'aggregationType', 'volume', 'issueIdentifier', 'article_number',\n",
       "       'pageRange', 'description', 'authkeywords', 'citedby_count',\n",
       "       'openaccess', 'freetoread', 'freetoreadLabel', 'fund_acr', 'fund_no',\n",
       "       'fund_sponsor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view column names\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view first 5 rows\n",
    "# df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.1021/acs.jchemed.1c00904', '10.5860/crln.82.9.428', '10.1021/acs.iecr.8b02573', '10.1021/acs.jchemed.6b00602', '10.5062/F4TD9VBX', '10.1021/acs.macromol.6b02005', '10.1186/s13321-016-0181-z', '10.1021/acs.chemmater.5b04431', '10.1021/acs.jchemed.5b00512', '10.1021/acs.jchemed.5b00375', '10.5860/crln.76.9.9384', '10.5860/crln.76.2.9259', '10.1126/science.346.6214.1258', '10.1021/ed400887t', '10.1016/j.acalib.2014.03.015', '10.5062/F4XS5SB9', '10.1021/ma300328u', '10.1021/mz200108a', '10.1021/ma201170y', '10.1021/ma200184u', '10.1021/cm102374t']\n"
     ]
    }
   ],
   "source": [
    "# We can index data from our new dataframe, df1.\n",
    "# For example, create a list of just the DOIs\n",
    "dois = df1.doi.tolist()\n",
    "print(dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Using NCBI Entrez Direct (EDirect) for Small Molecule Chemical Information Searching in a Unix Terminal',\n",
       " 'Using the linux operating system full-time tips and experiences from a subject liaison librarian',\n",
       " 'Analysis of the Frequency and Diversity of 1,3-Dialkylimidazolium Ionic Liquids Appearing in the Literature',\n",
       " 'Rapid Access to Multicolor Three-Dimensional Printed Chemistry and Biochemistry Models Using Visualization and Three-Dimensional Printing Software Programs',\n",
       " 'Text analysis of chemistry thesis and dissertation titles',\n",
       " 'Phototunable Thermoplastic Elastomer Hydrogel Networks',\n",
       " 'Programmatic conversion of crystal structures into 3D printable files using Jmol',\n",
       " 'Dangling-End Double Networks: Tapping Hidden Toughness in Highly Swollen Thermoplastic Elastomer Hydrogels',\n",
       " 'Replacing the Traditional Graduate Chemistry Literature Seminar with a Chemical Research Literacy Course',\n",
       " '3D Printed Block Copolymer Nanostructures',\n",
       " 'Hypotheses in librarianship: Applying the scientific method',\n",
       " 'Recruiting students to campus: Creating tangible and digital products in the academic library',\n",
       " 'Finally free',\n",
       " '3D printed molecules and extended solid models for teaching symmetry and point groups',\n",
       " 'Repurposing Space in a Science and Engineering Library: Considerations for a Successful Outcome',\n",
       " 'A model for managing 3D printing services in academic libraries',\n",
       " 'Morphological phase behavior of poly(RTIL)-containing diblock copolymer melts',\n",
       " 'Network formation in an orthogonally self-assembling system',\n",
       " 'Access to nanostructured hydrogel networks through photocured body-centered cubic block copolymer melts',\n",
       " 'Synthesis and ordered phase separation of imidazolium-based alkyl-ionic diblock copolymers made via ROMP',\n",
       " 'Thermally stable photocuring chemistry for selective morphological trapping in block copolymer melt systems']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of article titles\n",
    "titles = df1.title.tolist()\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 16, 23, 4, 11, 18, 6, 10, 24, 0, 0, 0, 94, 6, 34, 39, 31, 18, 44, 11]\n"
     ]
    }
   ],
   "source": [
    "# now a list of the cited by count\n",
    "cited_by = df1.citedby_count.tolist()\n",
    "print(cited_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sum of cited_by counts\n",
    "sum(cited_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Author Data in a Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Records for Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Emy Decker', '36660678600'], ['Lindsey Lowry', '57210944451'], ['Karen Chapman', '35783926100'], ['Kevin Walker', '56133961300'], ['Sara Whitver', '57194760730']]\n"
     ]
    }
   ],
   "source": [
    "# load a list of author names and Scopus AUIDs\n",
    "import csv\n",
    "with open('authors.txt') as infile:\n",
    "          rows = csv.reader(infile, delimiter='\\t')\n",
    "          author_list = list(rows)\n",
    "print(author_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of Scopus records for each author\n",
    "num_records = []\n",
    "for author,authorID in author_list:\n",
    "    \n",
    "    # query search\n",
    "    q = ScopusSearch('AU-ID' +'(' + authorID + ')', download=False)\n",
    "    num = q.get_results_size()\n",
    "    \n",
    "    # compile saved scopus data into a list of lists               \n",
    "    num_records.append([author, authorID, num])\n",
    "    \n",
    "    # delay one second between api calls to be nice to Elsevier servers\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Emy Decker', '36660678600', 14],\n",
       " ['Lindsey Lowry', '57210944451', 4],\n",
       " ['Karen Chapman', '35783926100', 29],\n",
       " ['Kevin Walker', '56133961300', 8],\n",
       " ['Sara Whitver', '57194760730', 4]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Record Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want the DOIs and cited by counts in a list\n",
    "cites = []\n",
    "for author,authorID in author_list:\n",
    "    \n",
    "    # query search\n",
    "    q = ScopusSearch('AU-ID' +'(' + authorID + ')')\n",
    "    \n",
    "    # create a dataframe\n",
    "    q_df = pd.DataFrame(q.results)\n",
    "       \n",
    "    # save DOIs to a list\n",
    "    doi = q_df.doi.tolist()\n",
    "    \n",
    "    # save citedby_count to a list\n",
    "    citedby_count = q_df.citedby_count.tolist()\n",
    "       \n",
    "    # compile saved scopus data into a list of lists               \n",
    "    cites.append([author, doi, citedby_count])\n",
    "    \n",
    "    # delay one second between api calls to be nice to Elsevier servers\n",
    "    time.sleep(1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Emy Decker',\n",
       "  ['10.1108/RSR-08-2021-0051',\n",
       "   '10.1080/1072303X.2021.1929642',\n",
       "   '10.1080/15367967.2021.1900740',\n",
       "   '10.1080/15367967.2020.1826951',\n",
       "   '10.1080/10691316.2020.1781725',\n",
       "   '10.1145/3347709.3347805',\n",
       "   '10.4018/978-1-5225-5631-2.ch09',\n",
       "   '10.1016/B978-0-08-102409-6.00007-9',\n",
       "   '10.1108/LM-10-2016-0078',\n",
       "   '10.1016/B978-0-08-100775-4.00010-8',\n",
       "   '10.1108/S0732-067120160000036013',\n",
       "   '10.4018/978-1-4666-8624-3',\n",
       "   '10.1108/S0065-2830(2013)0000037006',\n",
       "   '10.1108/07378831011096268'],\n",
       "  [0, 0, 7, 0, 0, 0, 3, 0, 6, 1, 2, 0, 0, 10]],\n",
       " ['Lindsey Lowry',\n",
       "  ['10.1080/1941126X.2021.1949153',\n",
       "   '10.5860/lrts.65n1.4-13',\n",
       "   '10.1080/00987913.2020.1733173',\n",
       "   '10.1080/1941126X.2019.1634951'],\n",
       "  [1, 0, 1, 0]]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The cites variable is a list of list with the data\n",
    "# view data for first two authors\n",
    "cites[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Emy Decker', '10.1108/RSR-08-2021-0051', 0],\n",
       " ['Emy Decker', '10.1080/1072303X.2021.1929642', 0],\n",
       " ['Emy Decker', '10.1080/15367967.2021.1900740', 7],\n",
       " ['Emy Decker', '10.1080/15367967.2020.1826951', 0],\n",
       " ['Emy Decker', '10.1080/10691316.2020.1781725', 0],\n",
       " ['Emy Decker', '10.1145/3347709.3347805', 0],\n",
       " ['Emy Decker', '10.4018/978-1-5225-5631-2.ch09', 3],\n",
       " ['Emy Decker', '10.1016/B978-0-08-102409-6.00007-9', 0],\n",
       " ['Emy Decker', '10.1108/LM-10-2016-0078', 6],\n",
       " ['Emy Decker', '10.1016/B978-0-08-100775-4.00010-8', 1],\n",
       " ['Emy Decker', '10.1108/S0732-067120160000036013', 2],\n",
       " ['Emy Decker', '10.4018/978-1-4666-8624-3', 0],\n",
       " ['Emy Decker', '10.1108/S0065-2830(2013)0000037006', 0],\n",
       " ['Emy Decker', '10.1108/07378831011096268', 10],\n",
       " ['Lindsey Lowry', '10.1080/1941126X.2021.1949153', 1],\n",
       " ['Lindsey Lowry', '10.5860/lrts.65n1.4-13', 0],\n",
       " ['Lindsey Lowry', '10.1080/00987913.2020.1733173', 1],\n",
       " ['Lindsey Lowry', '10.1080/1941126X.2019.1634951', 0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can transform this into a flat list as follows\n",
    "# credit to Avery Fernandez for help with this clever transformation!\n",
    "cites_flat = []\n",
    "for authors in range(len(cites)):\n",
    "    for doi in range(len(cites[authors][1])):\n",
    "        cites_flat.append([cites[authors][0], cites[authors][1][doi], cites[authors][2][doi]])\n",
    "cites_flat[0:18] # show first 2 author sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1108/RSR-08-2021-0051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1080/1072303X.2021.1929642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1080/15367967.2021.1900740</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1080/15367967.2020.1826951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1080/10691316.2020.1781725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1145/3347709.3347805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.4018/978-1-5225-5631-2.ch09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1016/B978-0-08-102409-6.00007-9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1108/LM-10-2016-0078</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1016/B978-0-08-100775-4.00010-8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1108/S0732-067120160000036013</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.4018/978-1-4666-8624-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1108/S0065-2830(2013)0000037006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Emy Decker</td>\n",
       "      <td>10.1108/07378831011096268</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lindsey Lowry</td>\n",
       "      <td>10.1080/1941126X.2021.1949153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lindsey Lowry</td>\n",
       "      <td>10.5860/lrts.65n1.4-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lindsey Lowry</td>\n",
       "      <td>10.1080/00987913.2020.1733173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lindsey Lowry</td>\n",
       "      <td>10.1080/1941126X.2019.1634951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                   1   2\n",
       "0      Emy Decker            10.1108/RSR-08-2021-0051   0\n",
       "1      Emy Decker       10.1080/1072303X.2021.1929642   0\n",
       "2      Emy Decker       10.1080/15367967.2021.1900740   7\n",
       "3      Emy Decker       10.1080/15367967.2020.1826951   0\n",
       "4      Emy Decker       10.1080/10691316.2020.1781725   0\n",
       "5      Emy Decker             10.1145/3347709.3347805   0\n",
       "6      Emy Decker      10.4018/978-1-5225-5631-2.ch09   3\n",
       "7      Emy Decker  10.1016/B978-0-08-102409-6.00007-9   0\n",
       "8      Emy Decker             10.1108/LM-10-2016-0078   6\n",
       "9      Emy Decker  10.1016/B978-0-08-100775-4.00010-8   1\n",
       "10     Emy Decker    10.1108/S0732-067120160000036013   2\n",
       "11     Emy Decker           10.4018/978-1-4666-8624-3   0\n",
       "12     Emy Decker  10.1108/S0065-2830(2013)0000037006   0\n",
       "13     Emy Decker           10.1108/07378831011096268  10\n",
       "14  Lindsey Lowry       10.1080/1941126X.2021.1949153   1\n",
       "15  Lindsey Lowry              10.5860/lrts.65n1.4-13   0\n",
       "16  Lindsey Lowry       10.1080/00987913.2020.1733173   1\n",
       "17  Lindsey Lowry       10.1080/1941126X.2019.1634951   0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add to dataframe\n",
    "cites_df = pd.DataFrame(cites_flat)\n",
    "cites_df.head(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Record Data to a file\n",
    "\n",
    "Here is one method if you want to loop over author queries and save all Scopus document data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Emy Decker', '36660678600'], ['Lindsey Lowry', '57210944451'], ['Karen Chapman', '35783926100'], ['Kevin Walker', '56133961300'], ['Sara Whitver', '57194760730']]\n"
     ]
    }
   ],
   "source": [
    "# load a list of author names and Scopus AUIDs\n",
    "import csv\n",
    "with open('authors.txt') as infile:\n",
    "          rows = csv.reader(infile, delimiter='\\t')\n",
    "          author_list = list(rows)\n",
    "print(author_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****this writes one file for each author dataset*****\n",
    "\n",
    "for authorName,authorID in author_list:\n",
    "    \n",
    "    # create new empty dataFrame on each loop\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # query search by Author ID\n",
    "    q = ScopusSearch('AU-ID' +'(' + authorID + ')')\n",
    "    \n",
    "    # convert to dataframe\n",
    "    df = pd.DataFrame(q.results)\n",
    "    \n",
    "    # Save to file\n",
    "    df.to_csv(str(authorName).replace(' ','_') + \"_\" + str(authorID) + \"_ScopusData\" + \".tsv\", sep = '\\t', index=False)\n",
    "    \n",
    "    # delay two seconds between api calls to be nice to Elsevier servers\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one of the files into pandas\n",
    "df_author3 = pd.read_csv('Karen_Chapman_35783926100_ScopusData.tsv', delimiter='\\t')\n",
    "# df_author3.head(5) # view first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    29.000000\n",
       "mean      5.034483\n",
       "std       5.703901\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       3.000000\n",
       "75%       8.000000\n",
       "max      21.000000\n",
       "Name: citedby_count, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get info about citedby_count\n",
    "df_author3.citedby_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                           29\n",
       "unique                                          11\n",
       "top       Behavioral and Social Sciences Librarian\n",
       "freq                                             8\n",
       "Name: publicationName, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get info about publication titles\n",
    "df_author3.publicationName.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get References via a Title Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Title Match Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search Scopus for all references containing 'ChemSpider' in the record title\n",
    "q2 = ScopusSearch('TITLE(ChemSpider)',download=False)\n",
    "q2.get_results_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat this in a loop\n",
    "titleWord_list = ['ChemSpider', 'PubChem', 'ChEMBL', 'Reaxys', 'SciFinder']\n",
    "\n",
    "# get number of Scopus records for each title search\n",
    "num_records_title = []\n",
    "for titleWord in titleWord_list:\n",
    "    \n",
    "    # query search\n",
    "    qt = ScopusSearch('TITLE' +'(' + titleWord + ')',download=False)\n",
    "    numt = qt.get_results_size()\n",
    "    \n",
    "    # compile saved scopus data into a list of lists               \n",
    "    num_records_title.append([titleWord,numt])\n",
    "    \n",
    "    # delay one second between api calls to be nice to Elsevier servers\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ChemSpider', 7],\n",
       " ['PubChem', 79],\n",
       " ['ChEMBL', 53],\n",
       " ['Reaxys', 8],\n",
       " ['SciFinder', 30]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_records_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Title Match Record Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download records and create a list of selected metadata\n",
    "titleWord_list = ['ChemSpider', 'PubChem', 'ChEMBL', 'Reaxys', 'SciFinder']\n",
    "scopus_title_data = []\n",
    "\n",
    "for titleWord in titleWord_list:\n",
    "    \n",
    "    # query search\n",
    "    qt = ScopusSearch('TITLE' +'(' + titleWord + ')') \n",
    "    \n",
    "    # create the dataframe\n",
    "    qt_df = pd.DataFrame(qt.results)\n",
    "    \n",
    "    # save DOIs to a list\n",
    "    doi = qt_df.doi.tolist()\n",
    "    \n",
    "    # save title to a list\n",
    "    title = qt_df.title.tolist()\n",
    "\n",
    "    # save coverDate to a list\n",
    "    coverDate = qt_df.coverDate.tolist()\n",
    "    \n",
    "    # compile saved scopus_title_data into a list of lists               \n",
    "    scopus_title_data.append([titleWord, doi, title, coverDate])\n",
    "    \n",
    "    # delay one second between api calls to be nice to Elsevier servers\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titleWord</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>coverDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChemSpider</td>\n",
       "      <td>10.1039/c5np90022k</td>\n",
       "      <td>Editorial: ChemSpider-a tool for Natural Produ...</td>\n",
       "      <td>2015-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChemSpider</td>\n",
       "      <td>10.1021/bk-2013-1128.ch020</td>\n",
       "      <td>ChemSpider: How a free community resource of d...</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChemSpider</td>\n",
       "      <td>10.1007/s13361-011-0265-y</td>\n",
       "      <td>Identification of \"known unknowns\" utilizing a...</td>\n",
       "      <td>2012-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChemSpider</td>\n",
       "      <td>10.1002/9781118026038.ch22</td>\n",
       "      <td>Chemspider: A Platform for Crowdsourced Collab...</td>\n",
       "      <td>2011-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChemSpider</td>\n",
       "      <td>10.1021/ed100697w</td>\n",
       "      <td>Chemspider: An online chemical information res...</td>\n",
       "      <td>2010-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>SciFinder</td>\n",
       "      <td>10.1021/ci0003808</td>\n",
       "      <td>Strategies for chemical reaction searching in ...</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>SciFinder</td>\n",
       "      <td>10.1002/nadc.19990471212</td>\n",
       "      <td>SciFinder scholar - Ein erster erfahrungsbericht</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>SciFinder</td>\n",
       "      <td>10.1021/cen-v074n025.p043</td>\n",
       "      <td>Chemical abstracts service launches release 2....</td>\n",
       "      <td>1996-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>SciFinder</td>\n",
       "      <td>None</td>\n",
       "      <td>Scientists online at their desktops SciFinder</td>\n",
       "      <td>1996-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>SciFinder</td>\n",
       "      <td>None</td>\n",
       "      <td>SciFinder from CAS: Information at the desktop...</td>\n",
       "      <td>1995-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      titleWord                         doi  \\\n",
       "0    ChemSpider          10.1039/c5np90022k   \n",
       "1    ChemSpider  10.1021/bk-2013-1128.ch020   \n",
       "2    ChemSpider   10.1007/s13361-011-0265-y   \n",
       "3    ChemSpider  10.1002/9781118026038.ch22   \n",
       "4    ChemSpider           10.1021/ed100697w   \n",
       "..          ...                         ...   \n",
       "172   SciFinder           10.1021/ci0003808   \n",
       "173   SciFinder    10.1002/nadc.19990471212   \n",
       "174   SciFinder   10.1021/cen-v074n025.p043   \n",
       "175   SciFinder                        None   \n",
       "176   SciFinder                        None   \n",
       "\n",
       "                                                 title   coverDate  \n",
       "0    Editorial: ChemSpider-a tool for Natural Produ...  2015-08-01  \n",
       "1    ChemSpider: How a free community resource of d...  2013-01-01  \n",
       "2    Identification of \"known unknowns\" utilizing a...  2012-01-01  \n",
       "3    Chemspider: A Platform for Crowdsourced Collab...  2011-05-03  \n",
       "4    Chemspider: An online chemical information res...  2010-11-01  \n",
       "..                                                 ...         ...  \n",
       "172  Strategies for chemical reaction searching in ...  2000-01-01  \n",
       "173   SciFinder scholar - Ein erster erfahrungsbericht  1999-01-01  \n",
       "174  Chemical abstracts service launches release 2....  1996-01-01  \n",
       "175      Scientists online at their desktops SciFinder  1996-01-01  \n",
       "176  SciFinder from CAS: Information at the desktop...  1995-07-01  \n",
       "\n",
       "[177 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a flat list of scopus_title_data\n",
    "scopus_title_data_flat = []\n",
    "for titleWord in range(len(scopus_title_data)):\n",
    "    for doi in range(len(scopus_title_data[titleWord][1])):\n",
    "        scopus_title_data_flat.append([scopus_title_data[titleWord][0], # titleWord\n",
    "                                       scopus_title_data[titleWord][1][doi], # doi\n",
    "                                       scopus_title_data[titleWord][2][doi], # title\n",
    "                                       scopus_title_data[titleWord][3][doi]]) # coverdate\n",
    "\n",
    "# add to dataFrame\n",
    "scopus_title_data_df = pd.DataFrame(scopus_title_data_flat)\n",
    "\n",
    "\n",
    "scopus_title_data_df.rename(columns={0:\"titleWord\",1: \"doi\",2: \"title\", 3: \"coverDate\"},\n",
    "                            inplace=True)\n",
    "scopus_title_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
